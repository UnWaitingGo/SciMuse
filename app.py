import os
import sys
import shutil
from pathlib import Path
import time
import gradio as gr
from omegaconf import OmegaConf
from dotenv import load_dotenv

# --- å¼•å…¥åç«¯æ¨¡å— ---
# ç¡®ä¿å½“å‰ç›®å½•åœ¨ sys.path ä¸­
sys.path.append(str(Path(__file__).parent))

from agents.planner_agent import PlannerAgent
from agents.retriever_agent import RetrieverAgent
from agents.reasoner_agent import ReasonerAgent
from agents.reviewer_agent import ReviewerAgent
from tools.pdf_parser import PDFParser
from tools.vector_db import VectorStoreManager
from schema import AgentDecision, ReasonerOutput

# åŠ è½½ç¯å¢ƒ
load_dotenv()

# --- å…¨å±€é…ç½®åˆå§‹åŒ– ---
CONFIG_PATH = "config.yaml"
if not os.path.exists(CONFIG_PATH):
    raise FileNotFoundError(f"Config file not found at {CONFIG_PATH}")

cfg = OmegaConf.load(CONFIG_PATH)

# åˆå§‹åŒ–å…¨å±€ Agent å®ä¾‹ (é¿å…æ¯æ¬¡è¯·æ±‚éƒ½é‡æ–°åŠ è½½æ¨¡å‹ï¼ŒèŠ‚çœå¼€é”€)
print("[*] Initializing Agents...")
planner = PlannerAgent(cfg)
retriever = RetrieverAgent(cfg)
reasoner = ReasonerAgent(cfg)
reviewer = ReviewerAgent(cfg)
print("[*] Agents Ready.")

# ==========================================
# æ ¸å¿ƒé€»è¾‘å°è£… (Generator æ¨¡å¼)
# ==========================================

def ingest_pdf(file_obj):
    """
    å¤„ç† PDF ä¸Šä¼ å’Œå…¥åº“
    """
    if file_obj is None:
        return "âš ï¸ è¯·å…ˆä¸Šä¼ ä¸€ä¸ª PDF æ–‡ä»¶ã€‚"
    
    pdf_path = file_obj.name # Gradio ä¸´æ—¶è·¯å¾„
    filename = os.path.basename(pdf_path)
    
    yield f"ğŸš€ å¼€å§‹å¤„ç†: {filename} ...\n"
    
    try:
        # 1. è§£æ
        yield f"ğŸ“„ [Parser] æ­£åœ¨è§£æ PDF ç»“æ„å’Œæå–å›¾ç‰‡ (è°ƒç”¨ MinerU)...\n"
        parser = PDFParser(cfg)
        text_chunks, figure_data = parser.parse_pdf(pdf_path)
        yield f"âœ… è§£æå®Œæˆ: æå–æ–‡æœ¬ {len(text_chunks)} æ®µ, å›¾ç‰‡ {len(figure_data)} å¼ ã€‚\n"
        
        # 2. å…¥åº“
        yield f"ğŸ’¾ [VectorDB] æ­£åœ¨è¿›è¡Œ VL å›¾ç‰‡ç†è§£ä¸å‘é‡åŒ–å­˜å‚¨...\n"
        vector_db = VectorStoreManager(cfg)
        vector_db.add_documents(text_chunks, figure_data)
        
        yield f"ğŸ‰ **å…¥åº“æˆåŠŸï¼**\næ–‡æ¡£ `{filename}` å·²å‡†å¤‡å¥½ï¼Œè¯·åˆ‡æ¢åˆ° Chat æ ‡ç­¾é¡µè¿›è¡Œæé—®ã€‚"
        
    except Exception as e:
        yield f"âŒ **å¤„ç†å¤±è´¥**: {str(e)}"


def chat_pipeline(user_message, history):
    """
    æ‰§è¡Œ RAG æµç¨‹ï¼Œå¹¶æµå¼è¾“å‡ºä¸­é—´æ­¥éª¤æ—¥å¿—å’Œæœ€ç»ˆå›å¤
    """
    if not user_message:
        yield history, "è¯·è¾“å…¥é—®é¢˜ã€‚"
        return

    # åˆå§‹åŒ–æ—¥å¿—ç¼“å†²åŒº
    logs = "### ğŸ¤– Agent Workflow Logs\n"
    
    # 1. Planner é˜¶æ®µ
    logs += "\n#### 1ï¸âƒ£ Planner Agent\n*æ­£åœ¨åˆ†æç”¨æˆ·æ„å›¾...*\n"
    yield  "æ­£åœ¨è§„åˆ’æ£€ç´¢ç­–ç•¥...", logs
    
    try:
        plan = planner.plan(user_message)
        logs += f"**Reasoning**: {plan.reasoning}\n"
        logs += f"**Search Queries**: `{plan.search_queries}`\n"
        logs += f"**Visual Check**: {'âœ… Yes' if plan.need_visual_understanding else 'âŒ No'}\n"
        yield "æ£€ç´¢è®¡åˆ’å·²ç”Ÿæˆ...", logs
    except Exception as e:
        logs += f"âŒ Planner Error: {str(e)}\n"
        yield f"ç³»ç»Ÿé”™è¯¯: {str(e)}", logs
        return

    # 2. Retriever é˜¶æ®µ
    logs += "\n#### 2ï¸âƒ£ Retriever Agent\n*æ­£åœ¨æ‰§è¡Œå‘é‡æ£€ç´¢...*\n"
    aggregated_context = ""
    
    for i, query in enumerate(plan.search_queries):
        logs += f"- ğŸ” Searching: *{query}* ...\n"
        yield f"æ­£åœ¨æ£€ç´¢: {query}...", logs
        
        res = retriever.run(query)
        # æˆªå–ä¸€éƒ¨åˆ†ç»“æœæ˜¾ç¤ºåœ¨æ—¥å¿—ä¸­ï¼Œé¿å…å¤ªé•¿
        preview = res[:200].replace('\n', ' ') + "..."
        logs += f"  - Result: {preview}\n"
        aggregated_context += f"\n--- Search Result for '{query}' ---\n{res}\n"

    # 3. Reasoner & Reviewer Loop
    logs += "\n#### 3ï¸âƒ£ Reasoner & Reviewer Loop\n*ç”Ÿæˆç­”æ¡ˆä¸è‡ªæˆ‘å®¡æŸ¥...*\n"
    
    max_retries = 2
    current_attempt = 0
    feedback = ""
    final_answer_obj = None
    
    while current_attempt <= max_retries:
        logs += f"\n**Attempt {current_attempt + 1}**\n"
        yield f"æ­£åœ¨ç”Ÿæˆå›ç­” (ç¬¬ {current_attempt+1} æ¬¡å°è¯•)...", logs
        
        # Reasoner
        effective_query = user_message
        if feedback:
            effective_query += f"\n(Critique from previous turn: {feedback})"
            
        draft_output = reasoner.run(
            query=effective_query,
            retriever_result=aggregated_context,
            vl_results=[] # å›¾ç‰‡ä¿¡æ¯å·²åœ¨ retrieved context ä¸­
        )
        logs += "âœï¸ **Draft Generated**.\n"
        
        # Reviewer
        review = reviewer.review(user_message, draft_output)
        logs += f"ğŸ§ **Review Decision**: `{review.decision.value}` (Score: {review.confidence_score})\n"
        
        if review.decision == AgentDecision.ACCEPT:
            final_answer_obj = draft_output
            logs += "âœ… **Passed!**\n"
            yield final_answer_obj.draft_answer, logs # æœ€ç»ˆè¾“å‡º
            break
        else:
            logs += f"âš ï¸ **Rejected**: {review.critique}\n"
            feedback = review.critique
            
            if review.feedback_for_retriever:
                logs += f"ğŸ”„ **Supplemental Search**: {review.feedback_for_retriever}\n"
                supp_evidence = retriever.run(review.feedback_for_retriever)
                aggregated_context += f"\n--- Supplemental ---\n{supp_evidence}\n"
            
            current_attempt += 1
            yield f"å›ç­”æœªé€šè¿‡å®¡æŸ¥ï¼Œæ­£åœ¨é‡è¯• ({current_attempt}/{max_retries})...", logs

    # Final Handling
    if final_answer_obj:
        # æ ¼å¼åŒ–æœ€ç»ˆå¼•ç”¨
        final_text = final_answer_obj.draft_answer
        if final_answer_obj.citations:
            final_text += "\n\n**ğŸ“š Citations:**\n" + "\n".join([f"- {c}" for c in final_answer_obj.citations])
        yield final_text, logs
    else:
        logs += "\nâŒ Failed to generate satisfactory answer.\n"
        yield f"æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•ï¼Œæˆ‘æ— æ³•ç”Ÿæˆæ»¡è¶³è´¨é‡è¦æ±‚çš„å›ç­”ã€‚\næœ€åä¸€æ¬¡è‰ç¨¿ï¼š\n{draft_output.draft_answer}", logs


# ==========================================
# Gradio UI æ„å»º
# ==========================================

# è‡ªå®šä¹‰ CSS ä¼˜åŒ–æ ·å¼
custom_css = """
#log_panel {
    background-color: #f9f9f9; 
    border: 1px solid #e0e0e0; 
    border-radius: 8px; 
    padding: 10px; 
    font-family: monospace; 
    font-size: 0.9em;
    height: 600px; 
    overflow-y: scroll;
}
"""

with gr.Blocks(title="SciMuse Agentic RAG", theme=gr.themes.Soft(), css=custom_css) as demo:
    gr.Markdown("# ğŸ§ª SciMuse: å¤šæ™ºèƒ½ä½“ç§‘ç ”æ–‡çŒ®åˆ†æç³»ç»Ÿ")
    gr.Markdown("åŸºäº Planner-Retriever-Reasoner-Reviewer æ¶æ„çš„æ·±åº¦æ–‡æ¡£ç†è§£åŠ©æ‰‹ã€‚")

    with gr.Tabs():
        # --- Tab 1: çŸ¥è¯†åº“å…¥åº“ ---
        with gr.Tab("ğŸ“‚ çŸ¥è¯†åº“ (Ingest)"):
            with gr.Row():
                with gr.Column(scale=1):
                    file_input = gr.File(
                        label="ä¸Šä¼  PDF è®ºæ–‡", 
                        file_types=[".pdf"],
                        file_count="single"
                    )
                    ingest_btn = gr.Button("ğŸš€ å¼€å§‹è§£æå…¥åº“", variant="primary")
                
                with gr.Column(scale=2):
                    ingest_log = gr.Textbox(
                        label="å¤„ç†æ—¥å¿—", 
                        placeholder="ç­‰å¾…ä¸Šä¼ ...", 
                        lines=15,
                        interactive=False
                    )
            
            # ç»‘å®šäº‹ä»¶
            ingest_btn.click(
                fn=ingest_pdf,
                inputs=file_input,
                outputs=ingest_log
            )

        # --- Tab 2: æ™ºèƒ½é—®ç­” ---
        with gr.Tab("ğŸ’¬ æ·±åº¦ç ”è¯» (Chat)"):
            with gr.Row():
                # å·¦ä¾§ï¼šèŠå¤©çª—å£
                with gr.Column(scale=2):
                    chatbot = gr.Chatbot(
                        label="Research Assistant",
                        type="messages", # Gradio 5.x æ¨èçš„æ–°æ ¼å¼
                        height=600,
                        avatar_images=(None, "https://api.dicebear.com/9.x/bottts-neutral/svg?seed=SciMuse") # å¯é€‰å¤´åƒ
                    )
                    with gr.Row():
                        msg_input = gr.Textbox(
                            show_label=False, 
                            placeholder="è¯·è¾“å…¥å…³äºè®ºæ–‡çš„é—®é¢˜ (ä¾‹å¦‚: Figure 3 å±•ç¤ºäº†ä»€ä¹ˆè¶‹åŠ¿?)...",
                            container=False,
                            scale=4
                        )
                        submit_btn = gr.Button("å‘é€", variant="primary", scale=1)
                
                # å³ä¾§ï¼šæ€ç»´é“¾æ—¥å¿—
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ§  Agent Thoughts (æ€ç»´é“¾)")
                    log_output = gr.Markdown(
                        value="Waiting for query...", 
                        elem_id="log_panel"
                    )

            # --- äº‹ä»¶å¤„ç†å‡½æ•° ---
            def user_msg(user_message, history):
                # 1. æŠŠç”¨æˆ·æ¶ˆæ¯åŠ å…¥å†å²å¹¶æ¸…ç©ºè¾“å…¥æ¡†
                if not user_message: return history, ""
                return history + [{"role": "user", "content": user_message}], ""

            def bot_response(history):
                # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
                user_message = history[-1]["content"]
                
                # è°ƒç”¨ç”Ÿæˆå™¨
                pipeline_generator = chat_pipeline(user_message, history)
                
                # åˆå§‹å“åº”å ä½
                history.append({"role": "assistant", "content": "..."})
                
                for response_text, log_text in pipeline_generator:
                    # æ›´æ–°æœ€åä¸€æ¡ Assistant çš„æ¶ˆæ¯
                    history[-1]["content"] = response_text
                    # åŒæ—¶æ›´æ–°å†å²å’Œä¾§è¾¹æ æ—¥å¿—
                    yield history, log_text

            # ç»‘å®šå›è½¦å’Œç‚¹å‡»äº‹ä»¶
            msg_input.submit(
                user_msg, [msg_input, chatbot], [chatbot, msg_input], queue=False
            ).then(
                bot_response, [chatbot], [chatbot, log_output]
            )
            
            submit_btn.click(
                user_msg, [msg_input, chatbot], [chatbot, msg_input], queue=False
            ).then(
                bot_response, [chatbot], [chatbot, log_output]
            )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0", 
        server_port=7860,
        share=False,    # å¦‚æœéœ€è¦å…¬ç½‘é“¾æ¥ï¼Œè®¾ä¸º True
        show_error=True
    )